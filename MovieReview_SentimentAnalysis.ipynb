{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd834d1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"3\"><center><font color='Blue'>**Sentiment Analysis of IMDB Movie Reviews**</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b923f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"3\">**Problem Statement**</font><br>Predict the sentiment of Movie Reviews in the ImDb dataset <br><br>\n",
    "<font size=\"3\">**Analysis Approach**</font>\n",
    "<div style=\"text-align: justify\"> \n",
    "    Movie reviews were pre-processed to remove html tags, non-alphabet characters and convert words in the review to lower case. To enhance the predictive performance reviews were de-noised by analyzing the frequency distribution of words used in reviews and developing a restrictive vocabulary based on specific cutoffs. Reviews transformed with this restricted vocabulary were tokenized to generate a feature representation and submitted to classification models.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632b6c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. [Read Dataset and Pre-Process Reviews](#read_dataset)\n",
    "2. [Exploratory Data Analysis](#EDA)\n",
    "3. [De-Noise Input Data](#denoise)\n",
    "4. [Feature Extraction (Tokenization)](#tokenize) <br>\n",
    "a. Term Frequency / Document Frequency (TfIdf) <br>\n",
    "b. Word Vector Representation (Embedding)\n",
    "5. [Models](#model)<br>\n",
    "a. Logistic Regression <br>\n",
    "b. Neural Network\n",
    "6. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38eeba72",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from utils import preprocess, sentence_to_avg, Embedding_model, predict\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f12263",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id='read_dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d062a85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' >Reading Dataset and Pre-processing Reviews</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac79311c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Reading Dataset\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "# Converting string categories to integers\n",
    "df['sentiment'][df['sentiment'] == 'positive'] = 1\n",
    "df['sentiment'][df['sentiment'] == 'negative'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cc3e50",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-Processing reviews\n",
    "p = df['review'].apply(preprocess)\n",
    "df['processed_review'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa668139",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reviews=df.processed_review\n",
    "sentiments=df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8266ef08",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mExample of a processed review:\u001b[0m \n",
      "one the other reviewers has mentioned that after watching just episode youll hooked they are right this exactly what happened with the first thing that struck about was its brutality and unflinching scenes violence which set right from the word trust this not show for the faint hearted timid this show pulls punches with regards drugs sex violence its hardcore the classic use the word called that the nickname given the oswald maximum security state penitentary focuses mainly emerald city experimental section the prison where all the cells have glass fronts and face inwards privacy not high the agenda city home many aryans muslims gangstas latinos christians italians irish and more scuffles death stares dodgy dealings and shady agreements are never far away would say the main appeal the show due the fact that goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romance doesnt mess around the first episode ever saw struck nasty was surreal couldnt say was ready for but watched more developed taste for and got accustomed the high levels graphic violence not just violence but injustice crooked guards wholl sold out for nickel inmates wholl kill order and get away with well mannered middle class inmates being turned into prison bitches due their lack street skills prison experience watching you may become comfortable with what uncomfortable viewing thats you can get touch with your darker side\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1mExample of a processed review:\\033[0m \\n{reviews[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3447ef97",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews: 50000 and Labels: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Reviews: {} and Labels: {}\".format(len(reviews), len(sentiments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1bdd0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id='EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49749def",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' >Exploratory Data Analysis of the reviews</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decaf083",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Word frequency were obtained**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81666758",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "total_counts = Counter() # Words in all reviews\n",
    "positive_counts = Counter() # Words in positive reviews\n",
    "negative_counts = Counter() # Words in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8688fe2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i, review in enumerate(reviews):    \n",
    "    if sentiments[i] == 1:\n",
    "        for word in review.split():\n",
    "            total_counts[word] += 1\n",
    "            positive_counts[word] += 1\n",
    "    else:\n",
    "        for word in review.split():\n",
    "            total_counts[word] += 1\n",
    "            negative_counts[word] += 1                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89229121",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most common words and their occurances \n",
      " [('the', 667363), ('and', 323870), ('this', 150854), ('that', 136923), ('was', 95526)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 most common words and their occurances \\n\",total_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd2bb3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id='denoise'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935feda6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' >Transform Dataset: De-Noise Input Reviews</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f773dc5c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sorted_words = sorted(total_counts, key=total_counts.get, reverse=False)\n",
    "freq_count = {word: total_counts[word] for word in sorted_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6c8813",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "value1 = 1\n",
    "value2 = 5\n",
    "low_freq_words = set()\n",
    "for word, cnt in freq_count.items():\n",
    "    if cnt > value1 and cnt < value2:\n",
    "        low_freq_words.add(word)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ebf430",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "min_count_words = ', '.join(list(low_freq_words)[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f41be603",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLow Frequency Words:\u001b[0m \n",
      "mcmurray, pities, discus, ormsby, mishmashes, com/~fedor, aatish, com/name/nm, beazely, wiggs, stadling, buddist, hooten, anniyan, birnleys, gantlet, flaubert, sangre, grievous, shemi, dabbles, tessie, submariner, docudramas, auf, interjects, infraction, haruna, selbys, chaise, maeve, chopsocky, croker, raisers, saltzman, goudry, classicism, lowpoints, *because*, vrajesh, lyta, coulter, estimations, motorboat, pinpoints, blowtorch, bettger, responders, vertov, fahcking, trivializing, granddaddys, trekkers, tucks, subscribed, undoes, kharbanda, derby, deliveryman, fiorella, widened, zir, huss, nekhron, fertilization, obtrusively, bombadil, plop, cassells, antecedent, sango, straubs, topgun, countrywoman, shonda, tutankhamen, hesslings, jove, safdie, reverberations, rapacious, writers/producers/directors, psychoactive, unspecific, mcculloch, significances, mori, lumbly, vogueing, insoluble, katts, rebhorn, japoteurs, zoology, gdr, contingency, goodknight, ballyhoo, rectitude, wierdo\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1mLow Frequency Words:\\033[0m \\n{min_count_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebe0fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"3\">**Determine MIN_COUNT:**</font> <br>Evaluating 'min_count_words' for different ranges it was found that words with low frequency (< 100), are mispelled, have typograhical errors or colloquial words. To minimize noise in the vocabulary words used less than 100 were also eliminated from analysis. **Based on this review of data the MIN_COUNT = 100 was used**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0637e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"3\">**Determine POLARITY_CUTOFF:**</font>  <br><div style=\"text-align: justify\"> Words like \"amazing\" are more likely in positive reviews and words like \"terrible\" are more frequent in negative reviews. Polarity is defined as the ratio of the frequency of the word in positive versus negative reviews. Restricting the vocabulary with a polarity cutoff by including high polarity words and excluding common words like \"the\" that appear in both positive and negative reviews is expected to enhance the predictive power of the review. Since words like \"the\" appear in both positive and negative reviews the ratio of these words is 1.0 and skews the polarity off-center. Hence log of the ratio is used to center the polarity distribution.   **Based on this analysis a polarity cutoff of 0.05 was used to construct the review vocabulary**</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e729e1cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter() # Ratio of words in positive / negative review\n",
    "for term, cnt in list(total_counts.most_common()):\n",
    "    if positive_counts[term]:\n",
    "        ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = np.log(ratio) # To center the polarity data around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4359f01a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.04386315777969167\n",
      "Pos-to-neg ratio for 'amazing' = 1.3538590853667367\n",
      "Pos-to-neg ratio for 'terrible' = -1.9099740788413335\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610c7c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"3\">**Create Review Vocabulary**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "204aa9c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "MIN_COUNT=100\n",
    "POLARITY_CUTOFF = 0.05\n",
    "review_vocab = set()\n",
    "for word, ratio in pos_neg_ratios.most_common():\n",
    "    if total_counts[word] > MIN_COUNT:\n",
    "        if((pos_neg_ratios[word] >= POLARITY_CUTOFF) or (pos_neg_ratios[word] <= -POLARITY_CUTOFF)):\n",
    "               review_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af063449",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of review vocabulary 6224\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of review vocabulary\", len(review_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f55b7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking review vocabulary\n",
    "'the' in list(review_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc944ccc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"3\">**Transform Dataset to words in vocabulary**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41a6af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for i, word in enumerate(review_vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49531419",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "transformed_dataset_int = []\n",
    "transformed_dataset = []\n",
    "for i, review in enumerate(reviews):\n",
    "    indices = []\n",
    "    words = []\n",
    "    for word in review.split(' '):\n",
    "        if word in word2index.keys():\n",
    "            indices.append(word2index[word])\n",
    "            words.append(word)\n",
    "    transformed_dataset_int.append(indices)\n",
    "    transformed_dataset.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dedd38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(transformed_dataset) == len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8f92c6d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Processed Training Reviews: 40000 Labels: 40000\n",
      "# Processed Test Reviews: 10000 Labels: 10000\n"
     ]
    }
   ],
   "source": [
    "#train dataset \n",
    "index = int(len(transformed_dataset)*0.80)\n",
    "X_train = transformed_dataset[:index]\n",
    "Y_train = list(df.sentiment[:index].values)\n",
    "#test dataset\n",
    "X_test = transformed_dataset[index:]\n",
    "Y_test = list(df.sentiment[index:].values)\n",
    "print(\"# Processed Training Reviews: {} Labels: {}\".format(len(X_train), len(Y_train)))\n",
    "print(\"# Processed Test Reviews: {} Labels: {}\".format(len(X_test), len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d781921",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id='tokenize'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b6aec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' > Feature Extraction (Tokenization)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374e6fd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"3\">**Create Term Frequency/Document frequency (TFIDF) tokenizer**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26c3d60d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# TFIDF needs strings\n",
    "TfIdf_X_train = []\n",
    "for a in X_train:\n",
    "    TfIdf_X_train.append(' '.join(a))\n",
    "    \n",
    "TfIdf_X_test = []\n",
    "for a in X_test:\n",
    "    TfIdf_X_test.append(' '.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7b75c93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Tfidf vectorizer\n",
    "TfIdf=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bac2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed train reviews\n",
    "X_train_TfIdf = TfIdf.fit_transform(TfIdf_X_train)\n",
    "#transformed test reviews\n",
    "X_test_TfIdf = TfIdf.transform(TfIdf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b73ac24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train_TfIdf.shape[0] == len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ee927",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"3\">**Generate word vectors with Word2Vec for tokenization**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0447c2b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# sg = 1 skip-gram, sg = 0 bag of words\n",
    "wv_vector_dim = 400\n",
    "WVmodel = Word2Vec(sg=1, size=wv_vector_dim, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20d1a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "WVmodel.build_vocab(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac66c2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43739979, 52036230)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WVmodel.train(X_train, total_examples = WVmodel.corpus_count,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d45c16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonderful', 0.4866514801979065),\n",
       " ('incredible', 0.4660269021987915),\n",
       " ('superb', 0.43346714973449707),\n",
       " ('outstanding', 0.4249274730682373),\n",
       " ('awesome', 0.4209737479686737),\n",
       " ('great', 0.3985666036605835),\n",
       " ('brilliant', 0.3958675265312195),\n",
       " ('breathtaking', 0.3937884569168091),\n",
       " ('fabulous', 0.3935829997062683),\n",
       " ('excellent', 0.38985300064086914)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity scores of words similar to \"amazing\" that is likely in positive reviews\n",
    "WVmodel.wv.most_similar(\"amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66d55c0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awful', 0.5576237440109253),\n",
       " ('horrible', 0.514610767364502),\n",
       " ('horrendous', 0.49778109788894653),\n",
       " ('atrocious', 0.4964660406112671),\n",
       " ('bad', 0.49113407731056213),\n",
       " ('horrid', 0.47501182556152344),\n",
       " ('lousy', 0.4350171983242035),\n",
       " ('abysmal', 0.40601277351379395),\n",
       " ('appalling', 0.39373308420181274),\n",
       " ('laughable', 0.3919409513473511)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity scores of words similar to \"terrible\" that is likely in negative reviews\n",
    "WVmodel.wv.most_similar(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9725c54",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "wv_file_name = \"imdb_word_vectors_\" + str(wv_vector_dim) + \"dim.kv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24636a42",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Save word vectors\n",
    "WVmodel.wv.save(wv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edebeae3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' > Models </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729a8fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"3\"><font color='Blue'><span style='background :yellow' >**Model: Logistic Regression**</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1feec1b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0206ef39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Fitting the model for tfidf features\n",
    "LR_tfidf=lr.fit(X_train_TfIdf, Y_train)\n",
    "##Predicting the model for tfidf features\n",
    "LR_tfidf_predict=lr.predict(X_test_TfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fb7635f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogistic Regression TfIDF Model Accuracy\u001b[0m 0.7327\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mLogistic Regression TfIDF Model Accuracy\\033[0m {}\".format(accuracy_score(Y_test, LR_tfidf_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60814d8f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"3\"><font color='Blue'><span style='background :yellow' >**Model: Neural Network with word embedding**</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165f7439",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "word_to_vec_map = KeyedVectors.load(wv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b7703d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat:   = 0.05760924132860845\n",
      "Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = Embedding_model(X_train, Y_train, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39ab01",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23ca30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style='color:Blue'> <span style='background :Yellow' > Conclusion </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4a67e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align: justify\"> To develop a predictive model movie review sentiments, reviews were de-noised with a restrictive vocabulary of high polarity words. The transformed reviews were tokenized using two tokenizers: Term-frequency/document frequency (TfIdf) and word vectors generated with Word2Vec. Logistic Regression was used to predict sentiment for reviews tokenized with TfIdf and a feed forward neural network was used to predict the sentiment with reviews tokenized with word vectors. <br><br>\n",
    "The neural network approach with word vector feature representation resulted in greater prediction accuracy (87%) compared to the Logistic Regression with Term Frequency/Document frequency (TfIdf) representation (73%). This finding is anticipated since word vectors capture the *similarily* between words unlike TfIdf that only *count* the occurances of words. Hence a word vector approach is likely to identify similar words in unseen test reviews not in the training dataset. As more words are used in the review to describe the positive or negative sentiment the strength of the association wiht the target sentiment is enhanced. A further improvment in predictive accuracy can be achieved by using BERT based language models that capture the context of the words in the review. </div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
